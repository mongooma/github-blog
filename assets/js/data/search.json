[ { "title": "Python: Cross-folder import", "url": "/posts/PythonCrossFolderImport/", "categories": "Project Management", "tags": "", "date": "2023-02-18 00:00:00 -0500", "snippet": "(For Python 3.7)Suppose you have a simple project which has the following folder structure:NewProject/ tools/ core.py workflows/ preprocessing/ cleaning.py ...", "content": "(For Python 3.7)Suppose you have a simple project which has the following folder structure:NewProject/ tools/ core.py workflows/ preprocessing/ cleaning.py analysis/ plots.py stats.py algorithms/ algos.py demo/ experiment.py tests/ test1.py test2.py main_script.py The main_script.py contains simple usage cases/test cases. The workflows/*/* has all the actual procedures.The tests has tests designed for different parts of this project.They might all need to import from tools/core.py. And for the scripts placed in analysis/, they need to also import from analysis/algorithms/algos.py.For algorithms/algos.py, it needs to import from tools/core.py.In order to let those cross-folder imports all work successfully, the “easiest” way is to create a package from this project. By creating a package, you could directly use the package root for referencing its modules.A wrong way to create the project packagePlace a setup.py under the root:Project_root/ setup.pyThe minimal setup.py for this purpose is simplyfrom setuptools import setupsetup( name=\"some_project\",)Even the name field is not necessary either. Python will automatically name it UNKNOWN if it’s missing.And then place an empty __init__.py under tools/ and algorithms/. (In Python 3.7 it is still suggested to do this even though it is not necessary for now.)Now build the package: from the Python environment, run python setup.py develop for development mode.After running python setup.py develop, the project folder containing __init__.py will be recognized as packages. And for Python 3.7, all the first-level subfolders are also visible everywhere in your python environment.So you could write in test1.py:import toolsfrom tools import corefrom core import ......Forget above: Better follow some conventionsThe above shows how to resolve cross-folder import for any arbitrary folder structures. It’s simple and carefree, but it’s not the best practice.Name clash issueIn the above process, you have created some packages that are only meaningful for the current project. You will forget about all these when you move on from this project and create another one of a similar purpose, which also contains tools/. You create the package for that project again and it will mess up your previous imports.It’s worth mentioning now: You are not creatinga package for this project, you simply creates the package for tools/ (and other first-level sub-folders namespaced-ly. It might throw error in some occassions if you also want to use them as packages. See this). And import NewProject will not have any effect anywhere.It would help if you first realized that the packaging means integrating it into your Python environment. You should avoid any name clash with the built-in/installed packages, and also be aware of any name clashes with your own in the future.Resolve name clash: Name the package by projectThe standard way to organize the package is to wrap it in a parent folder:NewProject/ # good convention to use the same name as the package name bin/ # the scripts as the entry points NewProject/ # this is the package for this project. ... The running python setup.py develop will create the package named NewProject. All the other sub-folders under NewProject could only be accessed from calling NewProject.For a reference to real-world packages, check out Numpy.Separate package (re-usable) and calling scriptsBefore creating the package, the above project could be re-organized asNewProject/ NewProject/ # the package content __init__.py tools/ __init__.py core.py algorithms/ __init__.py algos.py workflows/ preprocessing/ cleaning.py analysis/ plots.py stats.py demo/ experiment.py tests/ test1.py test2.py main_script.py # setup.pyAnd now you want to write the setup.py asfrom setuptools import setupsetup( name='NewProject', packages=[\"NewProject\"],)Then from within NewProject/NewProject, the algorithms/* could import from tools/* asfrom NewProject import toolsorfrom NewProject.tools.core import ...or other ways indicated by the doc." }, { "title": "Writing Tree traversal for Backtracking", "url": "/posts/backtracking/", "categories": "Algorithms", "tags": "", "date": "2023-02-15 00:00:00 -0500", "snippet": "Backtracking as orderly enumerationBacktracking searches all the possible solutions in the solution space in a systematic(orderly) way. It could provide an orderly enumeration for a general combina...", "content": "Backtracking as orderly enumerationBacktracking searches all the possible solutions in the solution space in a systematic(orderly) way. It could provide an orderly enumeration for a general combination problem with constraint in the format:From a set S, choose a combination C from S.Let this combination C satisfy g(C);ORLet this combination C satisfying g(C) achieve the best/max/min condition for a target function F(C).To make the enumeration orderly, we could first construct the complete solution space from the orderly selection:Let S = {s1, s2, s3, ..., s_N}Compose a combination C from:Choosing c1 = s_1 -&gt; Choosing c2 from S - {c_1} -&gt; Choosing c3 from S - {c_1, c_2} -&gt; ...This is useful when \\(S\\) is rather implicitly given, like in the subset-sum problems (e.g., Knapsack). But sometimes the \\(S\\) is not given explicitly, while the backtracking structure is more explicitly given already: Board games (e.g., crossword, N-queen problem), where the nodes are the board positions, and the edges are transitions from a cell to its adjacent cells. Multi-player Step games (e.g., Decision-making min-max), where the nodes are the game states, and the edges are the choices/strategies taken by the player at the source node. Sequential-conditional select (e.g., Resource allocation problems (e.g. PE151)): where the nodes are the current states of the resources, and the edges are the decisions to make at this step.The DFS traversal structure of the backtrackingA backtracking structure is a path traversal in a tree/graph, where the nodes are the elements in the \\(S\\). Every candidate solution is a full path. For a graph representation, the fewer edges in the graph, the less complexity in the traversal toward the final solution. The extreme trim-down of a graph is a tree, where the leaf nodes signify all the full paths from the root, and each should be considered and checked.So even though backtracking is a searching method considering the entire search space, it would be more efficient than brute-force/full enumeration because we could prune the subtree of a node when we have decided no more exploration is necessary from a sub-solution.Temporally Independent DFS search pathsSuppose we have already been given a tree of nodes and edges representing a problem. Backtracking is usually done by using depth-first-search as a subroutine.From a node n, each search branch is a path down from this node. The search branches are temporally independent – if not done in parallel. So sometimes, it is convenient to utilize this temporal locality feature to assign temporary values to the visited edges and nodes. For example, in the crossword game, it requires that a word is composed of non-overlapping cells in the board.Object/Procedure-oriented DFSThe search starting from the node n is done by calling f(n). It’s often confusing as to what this function is actually doing. Basically, there are two ways to phrase it: The “object-oriented” way: We continue the search from n down the different branches, and return whether any search is a success from n. The “precedure-oriented” way: We walk from n and explore all the paths from this n with possible early stops. The “object-oriented” way better describes the structure of the “root-tree/sub-trees and aggregation” search, which leads to –Important Locality feature of DFS f(n)By writing f(n, ...) specifically for the the tree rooted on node n, it simultaneously implicates an important feature of f(n, ...): f(n, ...) does not know anything about the subtrees besides that their root nodes are on the other end of the edges.That is: f(n, ...) does not access the properties of the subtree root nodes nbr.General Writing Style of f(n, …)By incorporating the above rule, it follows the general writing style for f(n):def f(n, state, params): if not continue_search(n): # no more branches from this node: node is None, some capacity limit is reached, state meets the termination, etc return ... res = [] for nbr in n.neighbours: if nbr is valid: new_state &lt;- state_change(nbr, state) #state change based on choice of nbr new_params &lt;- param_change(params) #usually state unaware, e.g. level based res &lt;- f(nbr, new_state, params) return aggregate(res)The aggregation() above is a general way to get the solution for this node n from the subtrees. But sometimes if we only need to get one valid solution (“any”) instead of returning all applicable,we could add the early break/return whenever we find a successfulf(nbr, ...).def f(n, ...): ... for nbr in n.neighbours: if nbr is valid: ... if f(nbr, ...): return True return FalseTo remind ourselves at all time the locality of f(n, ...), we could name it by the target function, like “found”, “matched”, “valid”, or the return type “max length”, “min cost”, etc.The end condition for f(n, …)For different problems, it might require different writing styles for the end condition section in f(n, ...).For the word matching problem, the end condition is:def match(n, matched_word, remain_to_match, ...) if len(remain_to_match) == 0: return matched_wordFor the N-queen problem, the end condition is:def valid(pos, current_placements, ...): if len(current_placements) == N: return TrueFor a binary tree max-depth problem, the end condition is:def maxDepth(root): if root is None: return 0Note for the binary tree: The end condition for f(n) when searching a binary tree is “when n is None”, but NOT “when n is a leaf node.”" }, { "title": "Geometric Sequence Sum", "url": "/posts/geometric_sequence/", "categories": "Maths", "tags": "", "date": "2023-02-09 00:00:00 -0500", "snippet": "", "content": "" }, { "title": "Illustration of Kosaraju's strongly connected components algorithm", "url": "/posts/kosaraju/", "categories": "Algorithms", "tags": "", "date": "2023-02-06 00:00:00 -0500", "snippet": "Kosaraju’s algorithm uses the DFS stack to determine the topological sorting of the strongly connected components of a directed graph. Complexity: \\(O(|V|+|E|)\\) (Two DFS; Creating components as ha...", "content": "Kosaraju’s algorithm uses the DFS stack to determine the topological sorting of the strongly connected components of a directed graph. Complexity: \\(O(|V|+|E|)\\) (Two DFS; Creating components as hashmaps and doing lookups take \\(O(|V|)\\))Since we are looking at components as nodes in the topological sorting, we focus on the DFS visiting/leaving time regarding a whole component. The visiting time \\(t^{visit}\\) for a component is the time when the first node in the component get visited, similarly the leaving time \\(t^{leave}\\) is for the last component node popped out of the DFS stack.Kosaraju’s utilizes the leaving times of the components to decide the topological sorting sequence.That is, if a component \\(C_i\\) is later in the sequence than \\(C_j\\), then we have for the leaving time \\(t^{leave}_i &lt; t^{leave}_j\\). The rationale is: After DFS leaves from the last node of \\(C_i\\), it will need to utilize a path through \\(C_j\\) to report back to the starting root.The algorithm goes:0. Directed graph G. Maintain a list L to receive the nodes popping out from the DFS stack.1. Repeatedly perform DFS from a random node in the remaining unvisited nodes in G. When finishing the exploration of a node (popping from the DFS stack), put it in the list L.2. Revert the list L to start from the last popped node. 3. Revert the graph edges of G.4. Take the first node from L, perform DFS to get the first component (source). 5. Check the next node until a node not in the first component, repeat 4 to get the second component.6. Repeat 4-5 until L is exhausted.The result is only a collection of the components. The directional edges (relationships) between the components are unknown.Reconstruct the directional edges between SCCTo reconstruct these directional edges, perform DFS from the source component (or multiple times if there are multiple source/target components). At each step on \\((u, v)\\), knowing that the current node \\(u\\) in component \\(C_i\\), record the linkage between the components by checking on \\(v\\) for every other component \\(C_j\\). Therefore, if we have \\(k\\) components, this will take \\(O(k * |E|)\\), and in the worst case \\(O(|V| * |E|)\\)." }, { "title": "Proof of Leetcode 11 \"Container with most water\"", "url": "/posts/container_with_most_water/", "categories": "Algorithms", "tags": "", "date": "2023-02-06 00:00:00 -0500", "snippet": "The solution to Leetcode “Container with most water” is a classic two-pointer/greedy algorithm. It sets up the two pointers at the left-most and right-most bar. Then, at each time, it moves the poi...", "content": "The solution to Leetcode “Container with most water” is a classic two-pointer/greedy algorithm. It sets up the two pointers at the left-most and right-most bar. Then, at each time, it moves the pointer previously pointing to the lower bar to the middle; during the process, records the results of reaching a higher bar, and finally stops and update the pointer position at a bar higher than the one pointed by the other pointer. It stops when left+1 == right.As with most of the greedy algorithms, the correctness of solution is nontrivial. So here is a simple proof by analysis to show the logic of this design.Let’s mark the bars with different type: a for non-checked bars. b2 for checked, but not used as final-pointer-location bars. b1 for the final-pointer-location bars for each round.Here we consider one round of “first move right against left, and then move left against right”:Denote the container configurations as (x, y), and for convenience use &lt; to indicate a larger container of the right side.During this round, we have recorded all the containers of configurations (b1, b1), (b1, b2) and (b2, b1).So we need to prove if the non-recorded configurations will have a larger container than the recorded ones. Now we prove this for the different cases:So the conclusion is that, for those non-recorded cases, we can always find one recorded case to upper-bound it. So chaining the rounds we will make sure the algorithm has the optimal solution in its search." }, { "title": "Tail Recursion", "url": "/posts/tail-recursion/", "categories": "Data Structure", "tags": "", "date": "2023-02-03 00:00:00 -0500", "snippet": "Each call from the recursion function will initiate its downstream calls, with this call as the “root”. The global root is the first call of the function.def f(n): # root call ... f(n-1) # r...", "content": "Each call from the recursion function will initiate its downstream calls, with this call as the “root”. The global root is the first call of the function.def f(n): # root call ... f(n-1) # recursive call ...In general (case 1 in the fig.), the root call will need the return value of the recursive call to compute. e.g., In backtracking, the searching direction is non-predictable (i.e., in a tree or a graph). Therefore, the root needs to redirect the search based on the return value of its recursive call.Another example is the divide-and-conquer situation, where the original problem is at the root node of a tree. At each level, the problem is divided into sub-problems. The final result has to be gathered at the root node because each non-root node is only aware of its own sub-problem.However, when the search direction is expressable, and the number of branches does not increase at each level, it could likely be a tail recursion.A recursion is said to be a tail recursion if the rest of the function does not rely on finishing the recursion step, so there is no need to maintain the full calling stack (case 2 in the fig.).The “tail recursion” got its name because, to make the compiler think the function does not depend on the return value of the recursive call, the recursive step must be at the tail part of the function body.This kind of writing is not a tail recursion:def f(n): return n + f(n-1)Because it’s equivalent todef f(n): res = f(n-1) res += n return res" }, { "title": "All-in-one MySQL techniques (beginner-intermediate)", "url": "/posts/SQLtechniques/", "categories": "Database", "tags": "", "date": "2023-02-03 00:00:00 -0500", "snippet": "Below is the copy of the gist project of my study notes for MySQL. The actual total study time is approximately ~20hrs, including my past experience with SQL and a weekend’s practice on Hackerrank....", "content": "Below is the copy of the gist project of my study notes for MySQL. The actual total study time is approximately ~20hrs, including my past experience with SQL and a weekend’s practice on Hackerrank. This guide is a quick reference of the common syntax, or a more simpler way to understand MySQL for those who are already familiar with other programming languages.During practicing SQL, I find that the most important thing is to realize that, MySQL is basically a language that manipulates tables. The tables are the data structure for MySQL as the lists, tuples and dictionaries for Python. Edit log, 3.28.2023: I have used amateur terms and case examples to explain about SQL. Now after visiting a course on database system (I was a computational maths undergrad) I have known better organizations for these concepts. But I still like to keep the trace of the understanding simply from practicing coding examples so I won’t perform a complete reconstruction of this study note. However, I will keep updating this post by adding references to technical resources.(For practicing on Hackerrank) Hackerrank features:Mysql vs Mysql server on Hackerrank with clause sometimes cause error in mysql environment -- comment cannot be written in the same line with the code In mysql, each select sentence is one line in the debugging message. In mysql server, the line number is in accordance with shown in the editor view. Language behaviors: sql does not differ lower and upper cases; The () are mandatory for sub-conditions (even when only one condition is present!) The = is used in the same way for == as “is equivalent to” The != is used the same way. The behavior of / is ambiguous. To ensure the integer result, use ceil(), floor() Use is NULL and is not NULL to check null values. = null will not be right. sqrt(), power() used in the same fashions. length() to get the length (number of bytes) of the string. Use from table1, table2, ... directly for the descarte product. Use limit n to select the first n rows of data. Rank desc on some column first to select the “last” rows. Run () union () to select both. union requires brackets. Use count(*) to get the number of rows in the table. Use max() to return null of the row does not exist. The window functions: row_number() gives distinct numbers, rank() gives non-distinct and non-continuous numbers, dense_rank() gives distinct and continuous numbers. String manipulationTo manipulate the string output, write something like:select concat(\"Hi, \", COUNT(NAME), ' of ', substr(occupation, 1, 3), 's.') from occupations group by occupation order by COUNT(NAME), occupation;Notice in the above example, the simple concat is used to format a string, substr(s, pos, num) acts as string[pos+1:pos+1+num]`` to get part of the string. See here for more ways to manipulate the string output.SelectThe basic select sentence is of structure:select COLUMN from TABLE where CONDITION To intepret the sentence, it’s actually of this orderselect COLUMN from (TABLE where CONDITION)The table will be loaded into the scope (all the column names). Therefore the column names are free to refer after select or in the CONTIDION.To use group by and aggregated functions:select MAX(COLUMN) from ((TABLE where CONDITION) group by COLUMN) Here the ordering is table where ... to get the slicing by some column value conditioning, and then group by ... to get the bags/sets of the rows, and finally the aggregation func to perform on the desired column.So notice the select syntax is better interpretated as “get”, rather than a active selection as if it’s a functional verb that should be run as the first move.And when using multiple tables, the join is written like:select COLUMN from ((TABLE1 left join TABLE2 on TABLE1.column = TABLE2.column) where CONDITION) ...Since obviously the first step is to get the complete joined table into the scope, then slicing and etc.To order the syntax for the select sentence it should be:select MAX(column) as col1, column2 as col2from (((TABLE1 left join TABLE2 on TABLE1.COL1 = TABLE2.COL2) where condition) group by column2) /* could not use the alias */order by col2 DESC; /* could use the alias */So the efficiency priority goes: Join multiple tables Slicing using column c conditioning Bagging the rows by some column a Ordering the rows by some column b (seems to be on the same level with select) Notice that 1 &amp; 2 will change the content of the table in the scope, and 2 as slicing should go after 1 joining.As for 3 and 4, even they might use different columns thus have no sequential dependency, but if first bagging, the next row ordering could have fewer rows to deal with, thus more efficient.For a more detailed explanation see here.Select from multiple tablesIn this example, the problem asks to gather the information from 5 tables under one company_code id. This should be a typical setting. And one solution from the discussion looks like:SELECT MAX(c.company_code), MAX(c.founder), (SELECT COUNT(DISTINCT lm.lead_manager_code) FROM Lead_Manager lm WHERE c.company_code = lm.company_code), (SELECT COUNT(DISTINCT sm.senior_manager_code) FROM Senior_Manager sm WHERE c.company_code = sm.company_code), (SELECT COUNT(DISTINCT m.manager_code) FROM Manager m WHERE c.company_code = m.company_code), (SELECT COUNT(DISTINCT e.employee_code) FROM Employee e WHERE c.company_code = e.company_code)FROM Company cGROUP BY c.company_codeORDER BY c.company_code ASCNotice the structure has a use of “implicit join”which has the structure asselect col1, col2, col3 /* the column names in table 1 and table 2 */from table1, table2where table1.foreign_key = table2.foreign_keyAnd it has combined multiple (select) into one “meta” select, and each sub-select will generate one column.But the implicit join is not encouraged to use nowadays (someone says it will throw out errors regarding null values, and it’s hard to write many conditions in where (?)). The explicit join could be written asSELECT C.company_code, C.founder, COUNT(DISTINCT L.lead_manager_code), COUNT(DISTINCT S.senior_manager_code), COUNT(DISTINCT M.manager_code), COUNT(DISTINCT E.employee_code)FROM Company C LEFT JOIN Lead_Manager L on C.company_code = L.company_codeLEFT JOIN Senior_Manager S on L.lead_manager_code = S.lead_manager_codeLEFT JOIN Manager M on S.senior_manager_code = M.senior_manager_codeLEFT JOIN Employee E on M.manager_code = E.manager_codeGROUP BY C.company_code, C.founderORDER BY C.company_code;(Notice the on .col1 = .col2 has to be aligned with the joining order ‘&lt;-‘)The structure of the giant joined table iscompany_code founder | company_code founder lead_manager_code | company_code founder lead_manager_code senior_manager_code | ...Notice the columns with the same names have been preserved within the giant table, and they could still be referred by table.col.This shows that join only links (as allowing the data communication between) the tables but has not actively done anything.Case…when…To output for different occasions, use case {when...then}*n else end as:select N, case when (P is null) then \"Root\" when (N in (select P from BST)) then \"Inner\" else \"Leaf\"endfrom BST;Notice the last case is else, and as all the script language asked for an end to signature the close of the segment.In the above example order by follows the table loading. It should be interpreted as order the rows first, and then do the select.Case…when… pivoting tableThe following example is to use case...when... to pivot a tablewith a as (select case when occupation='doctor' then name end as doctor , /* notice the column is singularly generated this way */ case when occupation='professor' then name end as professor , case when occupation='singer' then name end as singer, case when occupation='actor' then name end as actor, row_number() over (partition by occupation order by name) as ran from occupations)select min(doctor), min(professor), min(singer), min(actor) from a group by ranNotice the a as a temporary table is of the structure as following:a in the same effect as: (rows in the original order)(occupation) doctor_names ... actor_names ran---------------------------------------------------doctor name ... null 1doctor name ... null 2actor null ... name 1actor null ... name 2So when the case...when use a single case to generate one column based on the original column, the unfit row-column entries will yield null.The pivoting is partly finished at this point. But the row order column here is the key to align the ordering within each partition in the way:p1 p2 p3-----------v11 v21 v31v12 v22 v32v13 v23 v33... ... ...The effect is that the null values will be placed at the bottom of the column-rowset.The short-hand pivot simplifies the grammar, like this:select[Doctor], [Professor], [Singer], [Actor]from ( select row_number() over(partition by occupation order by name) /* agg() over (partition by ... order by ...)*/ /* use row_number()/rank()/dense_rank()/ to preserve the original partition data*/ /* ntile(n) will give n rows for each partition */ as rk, name, occupation from occupations) as t1pivot ( /* in the same effect as case ...when..., see above*/ min(name) /* applys on individual cell specified by the row number; but has to be an aggregation func; MIN, MAX both works*/ for occupation in (Doctor, Professor, Singer, Actor) /* here the for...in () takes \"table-value\" rather than \"string-value\", so no \"\" needed, write the \"table-value\" as-is here */) as t2;The t1 looks like:rk name occupation---------------------------------------1 name doctor 1 name actor 2 name doctor 2 name actor And then using pivot and specifying the pivoted columns. The min(name) will act on the individual rows, rather than the partitioned by occupation row-set, because of the constraint of the column tuple (rk, name), therefore the aggregation cannot go beyond the level of row.More about wherewhere could be intepreted as slicing, therefore the agg() could be used on the subset. It’s a more determinate row selecting.When need to have a set of choice within the case when... end in the condition, do not write the choices in the list case when condition then (c1, c2, c3), instead expand the subset to or:...where (col = (case when condition then c1) or (case when condition then c2) or (case when condition then c3))...(However there must be a better way to implement this!)The having clausehaving could be used to simplify the procedure of selecting only the part of the sub-bags, e.g. “the item count larger than k”. The grammar is likeselect count(*)from tablegroup by itemhaving count(*) &gt; k Note: Check the syntax group by ... having ....Use sub-table/temporary table/table aliasWith and table aliasAll “derived” tables should have alias:(select ...) tfrom () t where condition(t), the alias t is not seen by the where query.The temporary alias table could be lifted out to the beginning into the with clause.with t as ()select * from tWhen using multiple with, do this:with t1 as (),t2 as (/* could refer to t1 in here */)select * from t2 where ... /* t1 is visible to the where query while t2 is not*/To set a variable, place the query before the with:Set @variable = (); /**/with t1 as (),t2 as ()select * from t2 where ...;Therefore notice the with is within the select sentence as a clause.Info table and reference table Note: Also check for “Primary key and foreign key”.In this problem, it has two part of the information: the coder’s info, and the challenges’ info. The result returns the info of the coders based on their performance on the challenges. This could be interpreted as a “referring” relationship.In the original submission the classic way is to create join tables. But SQL has a structure called “correlated subquery” which deals exactly this. The structure looks like:select col from table t1where col operator ( select max(col) from table t2 where t1.id = t2.id)For example,SELECT last_name, salary, department_id FROM employees outer WHERE salary &gt; (SELECT AVG(salary) FROM employees WHERE department_id = outer.department_id group by department_id);Notice the group by is also on the correlation column to make sure the comparability.The effect of the above snippet is to compare the employee’s salary to the avg. in his department.It’s similar to comparing the coder’s performance to the difficulty of the challenges he solved. (See the different submission for the implementation.)And also for this problem." } ]
